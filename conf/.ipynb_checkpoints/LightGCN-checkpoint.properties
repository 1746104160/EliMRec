[hyperparameters]
layer_num=3
reg=1e-4
ssl_mode=both
description="Go lightGCN"
#the batch size for bpr loss training procedure
batch_size=2048
#the embedding size of lightGCN
recdim=64
#the learning rate
lr=.001
#the weight decay for l2 normalizaton
weight_decay=1e-4
#using the dropout or not
dropout=0
#the batch size for bpr loss training procedure
keepprob=.6
#the fold num used to split large adj matrix, like gowalla
a_fold=100
#the batch size for bpr loss training procedure
testbatch=128
#available datasets: {lastfm, gowalla, yelp2018, amazon-book,movielens}
dataset=movielens
#path to save weights
path=./checkpoints
#@k test list
topks=[10]
num_epoch=1000
#whether we use multiprocessing or not in test
multicore=0
#whether we use pretrained weight or not
pretrain=0
#random
seed=2022

#the path to movielens dataset
dataset_dir=E:/pycharmprojects/projects/data/movielens
#whether we load test data of movielens or not
is_load_test_dataset=1
#task for light and SSL, support:{normal, multitasks, pretrain}
train_type=normal
#verbose mode, show log in console
verbose=1
#epoch % [test_step] == 0: start testing
test_step=10
#weight initializator, support:{normal, xavier}
init=xavier
#optimization algorithms, support:{adam, adagrad}
optim=adam

#moco stat_dict file path
moco_weight_path=None
#log to server
log_api=
#save models or not, default not
save_flag=False

;adj_type=plain, norm, gcmc, pre
adj_type=pre
#other
A_split=False
